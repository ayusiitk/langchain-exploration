{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20cafc0a-7896-49c5-a6ef-5e4fac576a91",
   "metadata": {},
   "source": [
    "# This Notebook Explores using Langchain to extract important information and answer questions from complex documents\n",
    "# We are trying to answer some questions from a legal document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f898e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"userdata/\"\n",
    "with open('../keys/OpenAI.txt', 'r') as file:\n",
    "    # Read the content of the file and save it in a variable\n",
    "    openai_api_key = file.read().strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b634321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "\n",
    "# The vectorstore we'll be using\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# The LangChain component we'll use to get the documents\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# The easy document loader for text\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# The embedding engine that will convert our text to vectors\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38feb8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b461f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir = data_dir\n",
    "docs = []\n",
    "\n",
    "# Go through each folder\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    \n",
    "    # Go through each file\n",
    "    for file in filenames:\n",
    "        try: \n",
    "            # Load up the file as a doc and split\n",
    "            if(\".txt\" in file):\n",
    "                loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "            elif (\".pdf\" in file):\n",
    "                loader = PyPDFLoader(os.path.join(dirpath, file))\n",
    "            doc = loader.load()\n",
    "            text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
    "            docs.extend(text_splitter.split_documents(doc))\n",
    "        except Exception as e: \n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "683e0453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 8 documents that have an average of 1,726 characters (smaller pieces)\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of characters so we can see the average later\n",
    "num_total_characters = sum([len(x.page_content) for x in docs])\n",
    "\n",
    "print (f\"Now you have {len(docs)} documents that have an average of {num_total_characters / len(docs):,.0f} characters (smaller pieces)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76a00fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your embeddings engine ready\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# Embed your documents and combine with the raw text in a pseudo db. Note: This will make an API call to OpenAI\n",
    "docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9e6b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33828012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I don't know.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"write a similar services agreement between A Pvt. Ltd. and B Pvt. Ltd where A is service provider for cloud services to B\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd83230f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rachel is under 40 years old.\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"\n",
    "Rachel is 30 years old\n",
    "Bob is 45 years old\n",
    "Kevin is 65 years old\n",
    "\"\"\"\n",
    "\n",
    "question = \"Who is under 40 years old?\"\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "output = llm(context + question)\n",
    "\n",
    "# I strip the text to remove the leading and trailing whitespace\n",
    "print (output.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97492e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d521af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "# documents = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "vectorstore = Chroma.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c67e6f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29fb58f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=1, openai_api_key=openai_api_key), vectorstore.as_retriever(), memory=memory, return_source_documents=True)\n",
    "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=1, openai_api_key=openai_api_key), vectorstore.as_retriever(), return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5adb0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Using this sample document, draft an agreement for me between A and B\"\n",
    "result = qa({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6413e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b464319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='7  \\nName: [__]  \\nDesignation: [__]  \\n \\n \\n \\nFor and on behalf of [●] \\n \\n \\n_______________________  \\n \\nName: [ __] \\nDesignation: [__]', metadata={'source': 'userdata/sample_agreement.pdf', 'page': 6})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['source_documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b11885cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Start writing the document, and ask questions wherever required for drafting\"\n",
    "result = qa({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e213a2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  The best way to begin writing the document is by identifying each party involved, their roles and responsibilities, and what the main points of the agreement are. Ask questions throughout the drafting process as they come up, so that any issues can be addressed quickly.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9695dc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMBashChain chain...\u001b[0m\n",
      "Please write a bash script that prints 'Hello World' to the console.\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "```bash\n",
      "echo \"Hello World\"\n",
      "```\u001b[0m\n",
      "Code: \u001b[33;1m\u001b[1;3m['echo \"Hello World\"']\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m\"Hello World\"\n",
      "\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Hello World\"\\r\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMBashChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "text = \"Please write a bash script that prints 'Hello World' to the console.\"\n",
    "\n",
    "bash_chain = LLMBashChain.from_llm(llm, verbose=True)\n",
    "\n",
    "bash_chain.run(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d621cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import LLMChain, HypotheticalDocumentEmbedder\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "58b25381",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "llm = OpenAI(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c68334",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Please answer the user's question about the most recent state of the union address\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"question\"], template=prompt_template)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bac44951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.docstore.document import Document\n",
    "import requests\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "import pathlib\n",
    "import subprocess\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "843d450a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "search_index = Chroma.from_documents(docs, OpenAIEmbeddings(openai_api_key=openai_api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "636de9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "prompt_template = \"\"\"Use the context below to write a similar agreement with changes as described in Prompt:\n",
    "    Context: {context}\n",
    "    Prompt: {prompt}\n",
    "    Document:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"prompt\"]\n",
    ")\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c50c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"A is cloud service provider to B, scope of services to be defined\"\n",
    "def generate_agreement(prompt):\n",
    "    docs = search_index.similarity_search(prompt, k=4)\n",
    "    inputs = [{\"context\": doc.page_content, \"prompt\": prompt} for doc in docs]\n",
    "    print(chain.apply(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a165b92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': '\\nThis service agreement (“Agreement”) has been executed on the [●] day of [●], 20 [●] \\n \\nBY AND BETWEEN  \\n \\n(A) [●], a cloud service provider, duly incorporated and validly existing under the (Indian) Companies \\nAct, 2013, and having its registered office at [●] (hereinafter referred to as  the “Service Provider ”, which \\nexpression will, unless repugnant to the context, include it s successors and assigns) of the FIRST \\nPART  \\n \\nAND  \\n \\n(B) [●], a private limited company , duly incorporated and validly existing under the (Indian) Companies \\nAct, 2013 , and having  its registered office at [●] (hereinafter referred to as the “Company ”, \\nwhich expression will, unless repugnant to the context , include  its successors and assigns) of the \\nSECOND  PART . \\n \\nThe Service Provider and the Company are hereinafter individually referred to as a “Party” and collectively \\nas the “Parties”.  \\n \\n'}, {'text': '\\n\\n1.1 Scope of Services\\n\\n(a) During the Term (as defined hereinafter ) of this Agreement, if any additional services are \\nrequested by the Company B, the Parties will mutually agree , in writing,  on the scope of such \\nrevised services to be provided by the Service Provider A to the Company B  (the “ Additional \\nServices ”).  \\n \\n(b) Any such Additional Services being provided by the Service Provider A to the Company B will \\nbe subject to and in accordance with the ter ms of this Agreement.  \\n \\n1.2 Exclusivity   \\n \\nThe Parties agree that the appointment of the Service Provider A or providing the Services is on a \\n[non-exclusive basis].  \\n \\n2. SERVICE FEE AND INVOICES  \\n \\n2.1 Service Fee  \\n \\n(a) The Parties agree that the fee payable by the Company B for the Services will be a fixed \\nmonthly amount of INR [●] (Indian Rupees [●])  (the “ Fee”). \\n \\n(b) The Fee payable under this Agreement by the Company B to'}, {'text': '\\n\\n3.1 The Service Provider (A) will: \\n \\n(a) perform the Services in a timely manner;  \\n \\n(b) promptly provide to the Company (B) such information and relevant documentation as the \\nCompany may from time to time require for receiving the Services from the Service \\nProvider , including, without limitation, information with respect to the assets, the title to the \\nassets, encumbrances thereon, insurance, etc. ; and  \\n \\n(c) ensure that obligations under this Agreement are performed by a sufficient number of \\nappropriately experienced, qualified, competent, and trained personnel  (the “ Personnel ”). \\n \\n3.2 The Company (B) will: \\n  \\n(a) provide its assistance to the Service Provider (A), as may be reasonably required by the \\nService Provider from time to time for providing the Services to the Company in a timely \\nmanner;  \\n \\n(b) promptly provide to the Service Provider (A) such information and relevant documentation as \\nthe Service Provider may from time to time require for providing the Services to the \\nCompany , including, without limitation, information with respect'}, {'text': '\\n\\n6 The Parties acknowledge and accept that the Service Provider will, at all times during the Term of this Agreement, act and perform its obligations under this Agreement as an independent contractor and that the Service Provider will not be regarded as an employee, agent, or partner of the Company. Nothing in this Agreement is intended to, or will, operate to create a partnership or joint venture of any kind between the Company and the Service Provider. \\n\\n12.5 Assignment\\n\\nNeither Party will assign, transfer, charge or deal in any other manner with this Agreement or any rights or obligations hereunder, or purport to do any of these things or subcontract any or all of its obligations under this Agreement, to any third party without the prior written consent of the other Party. \\n\\n12.6 Waiver\\n\\nNo provision of this Agreement may be waived or changed except by a writing signed by the Party against whom such waiver or change is sought to be enforced. The failure to enforce a breach or default of this Agreement will not constitute a waiver of the right to enforce the same or any subsequent breach or default. \\n\\n12.7 Entire Agreement\\n\\nThis Agreement will constitute the entire agreement and understanding between the Parties and will substitute all the previous agreements'}]\n"
     ]
    }
   ],
   "source": [
    "generate_agreement(prompt=topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6bfb34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
